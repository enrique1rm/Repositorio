import pandas as pd
import Tarea3

from Tarea3 import df_closed
df = Tarea3.df_closed


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer

df = pd.read_csv("incident_event_log.csv")
df["opened_at"]  = pd.to_datetime(df["opened_at"], errors="coerce", dayfirst=True)
df["resolved_at"] = pd.to_datetime(df["resolved_at"], errors="coerce", dayfirst=True)
df["tiempo_resolver_horas"] = (df["resolved_at"] - df["opened_at"]).dt.total_seconds() / 3600

#variables explicativas
cat_var = ["priority", "impact"]                
num_var = ["reassignment_count", "reopen_count"]  
variables = cat_var + num_var


df_model = df[variables + ["tiempo_resolver_horas"]].dropna()
X = df_model[variables]
y = df_model["tiempo_resolver_horas"]


cat_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="constant", fill_value="missing")),
    ("onehot", OneHotEncoder(handle_unknown="ignore"))   # si prefieres: OneHotEncoder(handle_unknown='ignore', drop='first')
])
preprocessor = ColumnTransformer(transformers=[
    ("cat", cat_transformer, cat_var),
    ("num", "passthrough", num_var)
])

# Pipeline con Regresión Lineal
reg_pipeline = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("regressor", LinearRegression())
])


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

# Entrenar
reg_pipeline.fit(X_train, y_train)

#  Predecir y evaluar (RMSE calculado sin 'squared' param)
y_pred = reg_pipeline.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))    # <- aquí el cambio
mae  = mean_absolute_error(y_test, y_pred)
r2   = r2_score(y_test, y_pred)

print("RMSE:", rmse)
print("MAE :", mae)
print("R2  :", r2)


#  Extraer coeficientes y variables explicativas

pre = reg_pipeline.named_steps["preprocessor"]
ohe = pre.named_transformers_["cat"].named_steps["onehot"]

# Obtener nombres de categorías (robust: try get_feature_names_out, fallback a get_feature_names)
try:
    cat_names = ohe.get_feature_names_out(cat_var)   # sklearn >= 1.0
except AttributeError:
    # algunos sklearn antiguos usan get_feature_names()
    cat_names = ohe.get_feature_names(cat_var)


var_names = list(cat_names) + list(num_var)

# Extraer los coeficientes de la regresion
coefs = reg_pipeline.named_steps["regressor"].coef_
intercept = reg_pipeline.named_steps["regressor"].intercept_

coef_df = pd.DataFrame({"variable": var_names, "coef": coefs})
coef_df = coef_df.sort_values(by="coef", ascending=False).reset_index(drop=True)

print("\nIntercepto (β0):", intercept)
print("\nTop coeficientes (positivos -> aumentan horas):")
print(coef_df.head(12).to_string(index=False))
print("\nCoeficientes más negativos (reducción en horas):")
print(coef_df.tail(12).sort_values("coef").to_string(index=False))

